{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning: the statement by Tom M. Mitchell \n",
    "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "See <a href=\"https://www.coursera.org/learn/machine-learning\">https://www.coursera.org/learn/machine-learning</a>\n",
    "\n",
    "### Historical categories\n",
    "Historically, machine learning tasks are divided into three broad categories\n",
    "<ul>\n",
    "    <li><b>Supervised learning</b>: the model infers a function from supervised or labeled data. The training set consists of input-output pairs, and the goal of the model is to infer the correct mapping between the inputs and the outputs. The inferred function has to be general in order to yield the correct output from an unseen input. Important supervised learning algorithms are:\n",
    "        <ul>\n",
    "            <li>k-Nearest Neighbors</li>\n",
    "            <li>Linear Regression</li>\n",
    "            <li>Logistic Regression</li>\n",
    "            <li>Support Vector Machines (SVM)</li>\n",
    "            <li>Decision Tress and Random Forest</li>\n",
    "            <li>Neural networks (some - e.g.autoencoders and restricted Boltzamm machines - are unsupervised)</li>\n",
    "        </ul>   \n",
    "    </li>\n",
    "    <li><b>Unsupervised learning</b>: the data do not contain any additional information, and the goal of the model is to learn how to analyze the data, in order to \f",
    "nd patterns or structures. An unsupervised approach can be the goal of the model (e.g. in the case of clustering), or an intermediate data analysis step. Important supervised learning algorithms are:\n",
    "    <ul>\n",
    "        <li>Clustering (l-Means - Hierarchical Cluster Analysis (HCA) - Expectation Maximization</li>\n",
    "        <li>Visualization / Dimnesionality reduction (Principal Component Analysis (PCA) - Kernel PCA - Locally Linear Embedding (LLE) t-distributed Stochastci Neighbor Embedding (t-SNE)</li>\n",
    "        <li>Association rule learning ( Apriori - Eclat ) </li>\n",
    "    </ul>    \n",
    "    </li>\n",
    "    <li><b>Reinforcement learning</b>: in this case the learning model interacts directly with the environment, and learns from the consequences of its actions. The data consists of information about the environment and the set of available actions. When an action is performed, the RL-agent receives a reward, which indicates how positive was the action's outcome was. The goal of an RL-agent is to maximize the accumulated reward over time.<br/>\n",
    "        Reinforcement Learning problems with discrete actions can often be modeled as Markov Decision Processes (MDP). See also <a href=\"https://en.wikipedia.org/wiki/Dynamic_programming\">https://en.wikipedia.org/wiki/Dynamic_programming</a> and <a href=\"https://en.wikipedia.org/wiki/Bellman_equation\">https://en.wikipedia.org/wiki/Bellman_equation</a>.        \n",
    "    <ul>\n",
    "        <li>AlphaGo</li>\n",
    "    </ul>\n",
    "    </li>   \n",
    "</ul>\n",
    "\n",
    "### Categorization based on desired output of the learning system\n",
    "Another categorization of machine learning tasks arises when considering the desired output of the learning system:\n",
    "<ul>\n",
    "     <li>Classification:</li>\n",
    "    <li>Regression:</li>\n",
    "    <li>Clustering:</li>\n",
    "    <li>Density estimation:</li>\n",
    "    <li>Dimensionality reduction:</li>\n",
    "    <li>Representation learning:</li>\n",
    "    <li></li>\n",
    "    <li></li>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "\n",
    "### ANN\n",
    "<b>Artificial neural networks</b> (<tt>ANN</tt>) or <i>connectionist systems</i> are computing systems that  \"learn\" to perform tasks by considering examples, generally without being programmed with task-specific rules.\n",
    "\n",
    "### Python tools\n",
    "<ul>\n",
    "    <li><b>Python 3.7</b> and <b>pip</b> (19.2.2)</li>    \n",
    "    <li><b>NumPy</b>: add support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.</li>    \n",
    "    <li><b>Pandas</b>: offers data structures (DataFrame object) and operations for manipulating numerical tables and time series.</li>    \n",
    "    <li><b>Matplotlib</b>: provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+. </li>    \n",
    "    <li><b>Scikit-Learn</b>: features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy</li>    \n",
    "    <li><b>SciPy</b>:  contains modules for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ordinary differential equation(ODE) solvers and other tasks common in science and engineering.\n",
    "</ul>    \n",
    "\n",
    "###  Other tools\n",
    "\n",
    "<ul>\n",
    "    <li><b>TensorFlow</b>: a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks. It is used for both research and production at Google. See TF-Learn API (compatible with Scikit-Learn), TF-slim (to simplify building, training and evaluating neural networks), TensorBoard (great visualization tool). See also <a href=\"https://cloud.google.com/ml\" target=\"web\">https://cloud.google.com/ml</a></li>    \n",
    "    <li><b>Caffe</b>:  (Convolutional Architecture for Fast Feature Embedding) a deep learning framework written in C++ with a Python interface. It supports CNN, RCNN, LSTM and fully connected neural network designs. Caffe supports GPU- and CPU-based acceleration computational kernel libraries such as NVIDIA cuDNN and Intel MKL.</li>    \n",
    "    <li><b>PyTorch</b>:  open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. Differently from Tensorow or Caffe, that have a static view of the world, in PyTorch the computational graph is constructed dynamically.</li>    \n",
    "</ul>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159154.94309189534\n",
      "2.4805021344239853e+35\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "r =  1000000.0 / ( 2 * math.pi )\n",
    "print( r )\n",
    "crf = 100000 * 1000000.0 * ( 2 * math.pi )\n",
    "print( crf ** 3.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
